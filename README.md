# Dinosaur Classification Project

## ğŸ¦• Dataset

The dataset contains images of 15 different dinosaur species:

- Ankylosaurus
- Brachiosaurus
- Compsognathus
- Corythosaurus
- Dilophosaurus
- Dimorphodon
- Gallimimus
- Microceratus
- Pachycephalosaurus
- Parasaurolophus
- Spinosaurus
- Stegosaurus
- Triceratops
- Tyrannosaurus_Rex
- Velociraptor

## ğŸ“ Project Structure

```
dinosaur-classification/
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ config/config.py     # Python configuration (CONFIG dict)
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â”œâ”€â”€ dino_dataset.py  # Custom Dataset class
â”‚   â”‚   â””â”€â”€ dataset_split.py # Train/val/test split logic
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ model.py         # DinoNet CNN (ResNet-34 based)
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ transformers.py  # Data augmentation transforms
â”‚   â”‚   â”œâ”€â”€ utils.py         # Utility functions
â”‚   â”‚   â””â”€â”€ grad_cam.py      # Grad-CAM visualization
â”‚   â”œâ”€â”€ train.py             # Training script with advanced features
â”‚   â”œâ”€â”€ test.py              # Model evaluation and confusion matrix
â”‚   â””â”€â”€ visualize_gradcam.py # Grad-CAM visualization script
â”œâ”€â”€ data/                    # Dataset (15 dinosaur classes)
â”‚   â”œâ”€â”€ Ankylosaurus/
â”‚   â”œâ”€â”€ Brachiosaurus/
â”‚   â”œâ”€â”€ Compsognathus/
â”‚   â””â”€â”€ ... (12 more classes)
â”œâ”€â”€ models/                  # Saved model checkpoints
â”‚   â””â”€â”€ best_model.pth       # Best model by validation accuracy
â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ training.csv         # Training metrics per epoch
â”œâ”€â”€ results/                 # Evaluation results
â”‚   â”œâ”€â”€ confusion_matrix.png # Confusion matrix visualization
â”‚   â””â”€â”€ gradcam/             # Grad-CAM visualizations
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # This file
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <repository-url>
cd dinosaur-classification

# Create and activate venv (optional)
python -m venv .venv && .venv\\Scripts\\activate

# Install dependencies from requirements.txt
pip install -r requirements.txt
```

### 2. Data Preparation

The dataset is already organized in the following structure:
```
data/
â”œâ”€â”€ Ankylosaurus/
â”œâ”€â”€ Brachiosaurus/
â”œâ”€â”€ Compsognathus/
â”œâ”€â”€ Corythosaurus/
â”œâ”€â”€ Dilophosaurus/
â”œâ”€â”€ Dimorphodon/
â”œâ”€â”€ Gallimimus/
â”œâ”€â”€ Microceratus/
â”œâ”€â”€ Pachycephalosaurus/
â”œâ”€â”€ Parasaurolophus/
â”œâ”€â”€ Spinosaurus/
â”œâ”€â”€ Stegosaurus/
â”œâ”€â”€ Triceratops/
â”œâ”€â”€ Tyrannosaurus_Rex/
â””â”€â”€ Velociraptor/
```

### 3. Configuration

Configuration je Python dict u `src/config/config.py` (kljuÄ `CONFIG`).
Izmeni vrednosti (batch size, LR, epohe, putanje, split-ovi) po potrebi.

### 4. Training

```bash
# Train the model
python src/train.py
```

### 5. Testing & Evaluation

```bash
# Evaluate model performance and generate confusion matrix
python src/test.py

# Generate Grad-CAM visualizations
python src/visualize_gradcam.py
```

### 6. Available Scripts

- **`src/train.py`**: Main training script with advanced features
- **`src/test.py`**: Model evaluation with confusion matrix generation
- **`src/visualize_gradcam.py`**: Grad-CAM attention visualization

### 7. Checkpoints & Logs

- Best model by validation accuracy is saved to `models/best_model.pth`
- Training metrics per epoch are logged to `logs/training.csv` (train_loss, train_acc, val_loss, val_acc, lr)

## âš™ï¸ Configuration

`src/config/config.py` contains all hyperparameters and paths:

- **Data**: paths, batch size, image size, train/val/test split ratios
- **Model**: architecture (resnet34), dropout rate, pretrained weights
- **Training**: optimizer (sgd/adamw), learning rate, weight decay, epochs, label smoothing
- **Scheduler**: OneCycleLR or CosineAnnealing with configurable parameters
- **Advanced**: EMA settings, backbone freezing, differential learning rates
- **Paths**: model, log, and results directories
- **Reproducibility**: random seed for consistent results

## ğŸ“Š Features

### Training
- **Advanced Learning Rate Scheduling**: OneCycleLR with configurable parameters
- **Early Stopping**: Based on validation loss with configurable patience
- **Model Checkpointing**: Saves best model by validation accuracy
- **Mixed Precision Training**: Automatic Mixed Precision (AMP) on GPU
- **Exponential Moving Average (EMA)**: Optional EMA of model parameters
- **Backbone Freezing**: Configurable warmup epochs with frozen backbone
- **Differential Learning Rates**: Lower LR for pretrained backbone, higher for classifier
- **Label Smoothing**: Configurable label smoothing for better generalization
- **CSV Logging**: Detailed training metrics logged per epoch
- **Reproducibility**: Fixed random seeds for consistent results

### Model Architecture
- **ResNet-34 Backbone**: Pretrained ImageNet weights with custom classifier
- **Dropout Regularization**: Configurable dropout rate in final layers
- **Transfer Learning**: Leverages pretrained ResNet-34 features

### Dataset & Transforms
- **Stratified Split**: Train/val/test split (70/20/10 by default)
- **Advanced Augmentation**: RandomResizedCrop, flips, rotation, color jitter
- **ImageNet Normalization**: Standard preprocessing for pretrained models

### Evaluation & Visualization
- **Comprehensive Testing**: Accuracy, per-class metrics, confusion matrix
- **Grad-CAM Visualization**: Model attention heatmaps for interpretability
- **Confidence Thresholding**: Optional confidence-based prediction filtering
- **Detailed Metrics**: Per-class accuracy and confusion analysis

## ğŸ”§ Usage Examples

### Training the Model

```bash
# Train with default configuration
python src/train.py
```

### Evaluating Model Performance

```bash
# Run comprehensive evaluation
python src/test.py
```

This will:
- Load the best trained model
- Evaluate on test set with confidence thresholding
- Generate confusion matrix visualization
- Show per-class accuracy metrics
- Identify most confused class pairs

### Generating Grad-CAM Visualizations

```bash
# Generate attention heatmaps
python src/visualize_gradcam.py
```

This will:
- Load the trained model
- Select random samples from test set
- Generate Grad-CAM heatmaps showing model attention
- Save visualizations to `results/gradcam/`

### Modifying Configuration

Edit `src/config/config.py` to customize:

```python
CONFIG = {
    "data": {
        "batch_size": 64,        # Increase for faster training
        "train_split": 0.7,      # Adjust data splits
        "val_split": 0.2,
        "test_split": 0.1,
    },
    "model": {
        "dropout_rate": 0.3,     # Adjust regularization
        "pretrained": True,      # Use pretrained weights
    },
    "training": {
        "epochs": 100,           # More training epochs
        "learning_rate": 0.01,   # Adjust learning rate
        "optimizer": "adamw",    # Switch optimizer
    },
    "scheduler": {
        "type": "cosine",        # Use cosine annealing
    }
}
```

## ğŸ“ˆ Monitoring Training

- **CSV Logging**: Training metrics saved to `logs/training.csv`
  - Columns: epoch, train_loss, train_acc, val_loss, val_acc, lr
  - Can be opened in Excel or analyzed with pandas
- **Model Checkpoints**: Best model saved to `models/best_model.pth`
- **Results**: Evaluation results saved to `results/` directory

## ğŸ¯ Performance Tips

1. **Pretrained Weights**: Enable `pretrained: True` in config for better performance
2. **Learning Rate**: Current default is 0.03 with OneCycleLR scheduling
3. **Batch Size**: Increase `batch_size` if you have sufficient GPU memory
4. **EMA**: Enable Exponential Moving Average for more stable training
5. **Backbone Freezing**: Use `freeze_backbone_epochs` for gradual unfreezing
6. **Label Smoothing**: Current default is 0.1 for better generalization
7. **Early Stopping**: Monitor validation loss (patience=7 epochs)


